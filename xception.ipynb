{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN_p0d8JUzZQ",
        "outputId": "f2d6b90b-4721-4558-8386-65abbeac4227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "28Fwt43eVNWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztTdGeNIVkD4",
        "outputId": "feab894f-fff4-4d80-a859-4ca8adfa8265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WORK_DIR = '/content/drive/My Drive/Dataset/'\n",
        "CLASSES = ['normal', 'glaucoma', 'diabetic_retinopathy', 'cataract']\n",
        "IMG_SIZE = 224\n",
        "EPOCHS = 25\n",
        "INIT_LR = .001\n",
        "BS = 8\n",
        "default_image_size = tuple((256, 256))\n",
        "image_size = 0\n",
        "directory_root = '/content/drive/MyDrive/Dataset'\n",
        "width=256\n",
        "height=256\n",
        "depth=3"
      ],
      "metadata": {
        "id": "xbk8YeQtVwcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None\n",
        "\n",
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    for i, cl in enumerate(CLASSES):\n",
        "        files = listdir(WORK_DIR + cl)\n",
        "        for file in files:\n",
        "            image_list.append(convert_image_to_array(WORK_DIR + cl + '/' + file))\n",
        "            label_list.append(i)\n",
        "    print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHrEC5YYV3Tn",
        "outputId": "62783eec-cc80-409b-d30d-0fbad0406d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Image loading completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(label_list)\n",
        "\n",
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)\n",
        "set(label_binarizer.classes_)\n",
        "print(label_binarizer.classes_)\n",
        "np_image_list = np.array(image_list, dtype=np.float16) / 255.0\n",
        "print(\"[INFO] Spliting data to train, test\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) \n",
        "x_train.shape\n",
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4r1Jj_1Wcql",
        "outputId": "30fae1f9-9ecf-46c3-b3de-e6cd3606a72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3]\n",
            "[INFO] Spliting data to train, test\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3389, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "metadata": {
        "id": "oTOm0HwBWlRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, SeparableConv2D, \\\n",
        "     Add, Dense, BatchNormalization, ReLU, MaxPool2D, GlobalAvgPool2D\n",
        "\n",
        "def conv_bn(x, filters, kernel_size, strides=1):\n",
        "    x = Conv2D(filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=strides,\n",
        "               padding='same',\n",
        "               use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "FmZwBCKqWowa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sep_bn(x, filters, kernel_size, strides=1):\n",
        "    x = SeparableConv2D(filters=filters,\n",
        "                        kernel_size=3)\n",
        "x = MaxPool2D(pool_size=3, strides=2, padding='same')\n",
        "\n",
        "\n",
        "x = Add()([tensor, x])\n",
        "x = ReLU()(x)\n",
        "x = sep_bn(x, filters=728, kernel_size=3)\n",
        "x = ReLU()(x)\n",
        "x = sep_bn(x, filters=728, kernel_size=3)\n",
        "x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "\n",
        "tensor = conv_bn(tensor, filters=728, kernel_size=1, strides=2)\n",
        "x = Add()([tensor, x])\n",
        "x = ReLU()(x)\n",
        "return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_5i75qyyWujW",
        "outputId": "a04255d1-9ab0-43df-8d8b-5067a76108b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d65dc9eff3c9>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msep_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m728\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
          ]
        }
      ]
    }
  ]
}